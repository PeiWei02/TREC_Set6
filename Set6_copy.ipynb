{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used to search for files that match a specified pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xiao Hei Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the qrels file\n",
    "qrels_file_path = 'qrels.trec8.adhoc.csv'\n",
    "qrels_df = pd.read_csv(qrels_file_path, sep=' ', header=None, names=['query_id', 'ignore', 'doc_id', 'relevance'])\n",
    "\n",
    "#show qrels_dataframe\n",
    "qrels_df.head()\n",
    "print(qrels_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all CSV files in the input directory\n",
    "input_files = glob.glob('input/*.csv')\n",
    "\n",
    "# Create an empty list to store the input files dataframes\n",
    "input_dfs = []\n",
    "\n",
    "# Loop through each input CSV file\n",
    "for filename in input_files:\n",
    "    # Read the input CSV file into a dataframe\n",
    "    df = pd.read_csv(filename, sep='\\t', header=None)\n",
    "    # Append the dataframe to the list of dataframes\n",
    "    input_dfs.append(df)\n",
    "    \n",
    "raw_data = pd.concat(input_dfs, ignore_index=True)\n",
    "print('Shape of raw_data:', raw_data.shape)\n",
    "\n",
    "############################################## Data cleaning ##############################################\n",
    "\n",
    "# Loop through each input dataframe and filter out rows where does not meet the clean up requirement\n",
    "# 1. data_id  is not present in qrels_data_ids\n",
    "# 2. relevant_score equal to 0\n",
    "# 3. duplicate ranking\n",
    "\n",
    "# Extract the valid values from the third column of qrels_df\n",
    "qrels_data_ids = set(qrels_df.iloc[:, 2])\n",
    "\n",
    "cleaned_dfs = []\n",
    "\n",
    "for df in input_dfs:\n",
    "    # # # Get rows where the data id is present in the qrels data ids\n",
    "    # # df_with_present_data_id = df.iloc[:, 2].isin(qrels_data_ids)\n",
    "    \n",
    "    # # # Get rows where relevant_score does not equal 0\n",
    "    # # df_with_relevant_score_not_zero = df.iloc[:, 4] != 0\n",
    "    \n",
    "    # # Combine targeted rows for first and second rule\n",
    "    # cleaned_df = df[df_with_present_data_id & df_with_relevant_score_not_zero]\n",
    "\n",
    "    # Get rows where ranking is not duplicated\n",
    "    cleaned_df = df\n",
    "    cleaned_dfs.append(cleaned_df)\n",
    "\n",
    "# Print the shape of the cleaned data\n",
    "print(\"this is input data:\", cleaned_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column names\n",
    "columns = ['query_id', 'ignore', 'doc_id', 'rank', 'score', 'ignore2']\n",
    "\n",
    "# Create an empty list to store the cleaned dataframes\n",
    "cleaned_dfs_with_names = []\n",
    "\n",
    "# Iterate over each cleaned dataframe in cleaned_dfs\n",
    "for df in cleaned_dfs:\n",
    "    # Rename the columns\n",
    "    df = df.rename(columns=dict(enumerate(columns)))\n",
    "    # Append the renamed dataframe to the new list\n",
    "    cleaned_dfs_with_names.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleaned_dfs_with_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the dataframes and print the first and third columns\n",
    "for i, cleaned_df in enumerate(cleaned_dfs_with_names):\n",
    "    print(f\"Columns of dataframe {i+1}:\")\n",
    "    print(\"First column:\", cleaned_df.iloc[:, 0])\n",
    "    print(\"Third column:\", cleaned_df.iloc[:, 2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Analysis Part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = []\n",
    "for df in cleaned_dfs_with_names:\n",
    "    cleaned_df_with_qrel = pd.merge(df, qrels_df, on=['query_id','doc_id'], how='left')\n",
    "    cleaned_df_with_qrel['relevance'] = cleaned_df_with_qrel['relevance'].fillna(0)\n",
    "    merged_df.append(cleaned_df_with_qrel)\n",
    "    print(cleaned_df_with_qrel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics_precisions = []\n",
    "calculate_metrics_avg_precisions = []\n",
    "temp = 0\n",
    "\n",
    "for df in merged_df:\n",
    "    freq = df['relevance'].value_counts()[1]\n",
    "    temp = temp + freq\n",
    "\n",
    "for index, df in enumerate(merged_df):\n",
    "    # group by query_id\n",
    "    grouped = df.groupby('query_id')\n",
    "\n",
    "    # calculate precision for top 10\n",
    "    precisions = grouped.apply(lambda x: np.sum(x['relevance'].head(10)) / 10)\n",
    "    calculate_metrics_precisions.append(precisions)\n",
    "\n",
    "    # calculate average precision\n",
    "    avg_precisions = grouped.apply(lambda x: np.nan_to_num(np.sum(x['relevance'] * np.cumsum(x['relevance']) / np.arange(1, len(x['relevance']) + 1)) / np.sum(x['relevance']), nan=0.00000))\n",
    "    calculate_metrics_avg_precisions.append(avg_precisions)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate_metrics_precisions = []\n",
    "calculate_metrics_avg_precisions = []\n",
    "for df in merged_df:\n",
    "    # group by query_id\n",
    "    grouped = df.groupby('query_id')\n",
    "\n",
    "    # calculate precision for top 10\n",
    "    precisions = grouped.apply(lambda x: np.sum(x['relevance'].head(10)) / 10)\n",
    "    calculate_metrics_precisions.append(precisions)\n",
    "\n",
    "    # calculate average precision\n",
    "    avg_precisions = grouped.apply(lambda x: np.sum(x['relevance'] * np.cumsum(x['relevance']) / np.arange(1, len(x['relevance']) + 1)) / np.sum(x['relevance']))\n",
    "    calculate_metrics_avg_precisions.append(avg_precisions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"calculate_metrics_precisions\",calculate_metrics_precisions)\n",
    "print(\"calculate_metrics_avg_pr\",calculate_metrics_avg_precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming the lists have the same length\n",
    "results_df = pd.concat([pd.DataFrame(calculate_metrics_precisions).T],  axis=1)\n",
    "results_df.columns = [\"Precision@10_\" + str(i) for i in range(15)] \n",
    "\n",
    "# calculate the overall precision@10\n",
    "overall_precision = results_df.mean(axis=1)\n",
    "\n",
    "# add the new column to the DataFrame\n",
    "results_df['Overall Precision@10'] = overall_precision\n",
    "\n",
    "# calculate the overall row precision@10\n",
    "overall_precision_row = results_df.mean(axis=0)\n",
    "\n",
    "# add the new row to the DataFrame\n",
    "results_df.loc[\"Overall\"] = overall_precision_row\n",
    "\n",
    "# show the new table\n",
    "print(results_df)\n",
    "results_df.to_csv('resultsT10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat([pd.DataFrame(calculate_metrics_avg_precisions).T],  axis=1)\n",
    "results_df.columns = [\"MAP_\" + str(i) for i in range(15)] \n",
    "\n",
    "\n",
    "# calculate the overall precision@10\n",
    "overall_precision = results_df.mean(axis=1)\n",
    "\n",
    "# add the new column to the DataFrame\n",
    "results_df['Overall Precision@10'] = overall_precision\n",
    "\n",
    "# calculate the overall row precision@10\n",
    "overall_precision_row = results_df.mean(axis=0)\n",
    "\n",
    "# add the new row to the DataFrame\n",
    "results_df.loc[\"Overall\"] = overall_precision_row\n",
    "\n",
    "# show the new table\n",
    "print(results_df)\n",
    "results_df.to_csv('resultsMAP.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
