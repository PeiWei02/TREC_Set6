{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used to search for files that match a specified pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\acer\\anaconda3\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pandas) (2023.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of raw_data: (689266, 6)\n",
      "Shape of cleaned_data: (290603, 6)\n"
     ]
    }
   ],
   "source": [
    "# import qrels csv file\n",
    "qrels_file_path = 'qrels.trec8.adhoc.csv'\n",
    "qrels_df = pd.read_csv(qrels_file_path, sep=' ', header=None)\n",
    "\n",
    "# Get a list of all CSV files in the input directory\n",
    "input_files = glob.glob('input/*.csv')\n",
    "\n",
    "# Create an empty list to store the input files dataframes\n",
    "input_dfs = []\n",
    "\n",
    "# Loop through each input CSV file\n",
    "for filename in input_files:\n",
    "    # Read the input CSV file into a dataframe\n",
    "    df = pd.read_csv(filename, sep='\\t', header=None)\n",
    "    # Append the dataframe to the list of dataframes\n",
    "    input_dfs.append(df)\n",
    "    \n",
    "raw_data = pd.concat(input_dfs, ignore_index=True)\n",
    "print('Shape of raw_data:', raw_data.shape)\n",
    "\n",
    "############################################## Data cleaning ##############################################\n",
    "\n",
    "# Loop through each input dataframe and filter out rows where does not meet the clean up requirement\n",
    "# 1. data_id  is not present in qrels_data_ids\n",
    "# 2. relevant_score equal to 0\n",
    "# 3. duplicate ranking\n",
    "\n",
    "# Extract the valid values from the third column of qrels_df\n",
    "qrels_data_ids = set(qrels_df.iloc[:, 2])\n",
    "\n",
    "cleaned_dfs = []\n",
    "\n",
    "for df in input_dfs:\n",
    "    # Get rows where the data id is present in the qrels data ids\n",
    "    df_with_present_data_id = df.iloc[:, 2].isin(qrels_data_ids)\n",
    "    \n",
    "    # Get rows where relevant_score does not equal 0\n",
    "    df_with_relevant_score_not_zero = df.iloc[:, 4] != 0\n",
    "    \n",
    "    # Combine targeted rows for first and second rule\n",
    "    cleaned_df = df[df_with_present_data_id & df_with_relevant_score_not_zero]\n",
    "\n",
    "    # Get rows where ranking is not duplicated\n",
    "    cleaned_df = cleaned_df.drop_duplicates(subset=[4])\n",
    "    cleaned_dfs.append(cleaned_df)\n",
    "\n",
    "# Concatenate all cleaned dataframes into a single dataframe\n",
    "cleaned_data = pd.concat(cleaned_dfs, ignore_index=True)\n",
    "\n",
    "# Print the shape of the cleaned data\n",
    "print('Shape of cleaned_data:', cleaned_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>401</td>\n",
       "      <td>Q0</td>\n",
       "      <td>FT924-5091</td>\n",
       "      <td>0</td>\n",
       "      <td>10015.175781</td>\n",
       "      <td>acsys8aln2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>401</td>\n",
       "      <td>Q0</td>\n",
       "      <td>FBIS3-39240</td>\n",
       "      <td>1</td>\n",
       "      <td>10014.111328</td>\n",
       "      <td>acsys8aln2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>401</td>\n",
       "      <td>Q0</td>\n",
       "      <td>FT924-4470</td>\n",
       "      <td>2</td>\n",
       "      <td>10013.638672</td>\n",
       "      <td>acsys8aln2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>401</td>\n",
       "      <td>Q0</td>\n",
       "      <td>FBIS4-18182</td>\n",
       "      <td>3</td>\n",
       "      <td>10013.591797</td>\n",
       "      <td>acsys8aln2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>401</td>\n",
       "      <td>Q0</td>\n",
       "      <td>FBIS3-59055</td>\n",
       "      <td>4</td>\n",
       "      <td>10013.441406</td>\n",
       "      <td>acsys8aln2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1            2  3             4           5\n",
       "0  401  Q0   FT924-5091  0  10015.175781  acsys8aln2\n",
       "1  401  Q0  FBIS3-39240  1  10014.111328  acsys8aln2\n",
       "2  401  Q0   FT924-4470  2  10013.638672  acsys8aln2\n",
       "3  401  Q0  FBIS4-18182  3  10013.591797  acsys8aln2\n",
       "4  401  Q0  FBIS3-59055  4  10013.441406  acsys8aln2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QRELS check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>ignore</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>401</td>\n",
       "      <td>0</td>\n",
       "      <td>FBIS3-10009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>401</td>\n",
       "      <td>0</td>\n",
       "      <td>FBIS3-10059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>401</td>\n",
       "      <td>0</td>\n",
       "      <td>FBIS3-10142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>401</td>\n",
       "      <td>0</td>\n",
       "      <td>FBIS3-1026</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>401</td>\n",
       "      <td>0</td>\n",
       "      <td>FBIS3-10502</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id  ignore       doc_id  relevance\n",
       "0       401       0  FBIS3-10009          0\n",
       "1       401       0  FBIS3-10059          0\n",
       "2       401       0  FBIS3-10142          0\n",
       "3       401       0   FBIS3-1026          0\n",
       "4       401       0  FBIS3-10502          0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the qrels file\n",
    "qrels_file_path = 'qrels.trec8.adhoc.csv'\n",
    "qrels_df = pd.read_csv(qrels_file_path, sep=' ', header=None, names=['query_id', 'ignore', 'doc_id', 'relevance'])\n",
    "\n",
    "#show qrels_dataframe\n",
    "qrels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input\\\\input.acsys8aln2.csv', 'input\\\\input.apl8c621.csv', 'input\\\\input.att99ate.csv', 'input\\\\input.disco1.csv', 'input\\\\input.Flab8atd2..csv', 'input\\\\input.GE8ATD3..csv', 'input\\\\input.ibms99a.csv', 'input\\\\input.INQ601.csv', 'input\\\\input.isa50t.csv', 'input\\\\input.mds08a3.csv', 'input\\\\input.MITSLStd.csv', 'input\\\\input.ok8alx.csv', 'input\\\\input.pir9Atd0.csv', 'input\\\\input.READWARE.csv', 'input\\\\input.Sab8A1.csv']\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all input files in the input directory\n",
    "input_files = glob.glob('input/*.csv')\n",
    "\n",
    "#check the input file list\n",
    "print(input_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Temp/ipykernel_12172/4247895359.py:17: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  avg_precisions = grouped.apply(lambda x: np.sum(x['relevance'] * np.cumsum(x['relevance']) / np.arange(1, len(x['relevance']) + 1)) / np.sum(x['relevance']))\n"
     ]
    }
   ],
   "source": [
    "# Create an empty dictionary to store the system scores\n",
    "system_scores = {}\n",
    "\n",
    "# Loop through each input file\n",
    "for filename in input_files:\n",
    "    # Load the input file\n",
    "    input_df = pd.read_csv(filename, sep='\\t', header=None, names=['query_id', 'ignore', 'doc_id', 'rank', 'score', 'ignore2']) \n",
    "    input_df.head()\n",
    "\n",
    "    # Merge the input file with the qrels to get the relevance scores\n",
    "    merged_df = pd.merge(input_df, qrels_df, on=['query_id', 'doc_id'], how='left')\n",
    "    merged_df.head()\n",
    "\n",
    "    # Compute precision@10 and MAP per query\n",
    "    grouped = merged_df.groupby('query_id')\n",
    "    precisions = grouped.apply(lambda x: np.sum(x['relevance'].iloc[:10]) / 10)\n",
    "    avg_precisions = grouped.apply(lambda x: np.sum(x['relevance'] * np.cumsum(x['relevance']) / np.arange(1, len(x['relevance']) + 1)) / np.sum(x['relevance']))\n",
    "\n",
    "    # Store the scores for this system\n",
    "    system_name = filename.split('/')[-1].split('.')[0]\n",
    "    system_scores[system_name] = pd.DataFrame({'precision@10': precisions, 'MAP': avg_precisions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          input\\input          \n",
      "         precision@10       MAP\n",
      "query_id                       \n",
      "401               0.2  0.133187\n",
      "402               0.5  0.240247\n",
      "403               0.6  0.737960\n",
      "404               0.2  0.206948\n",
      "405               0.3  0.164085\n",
      "406               0.5  0.438768\n",
      "407               0.8  0.502876\n",
      "408               0.3  0.242085\n",
      "409               0.1  0.050198\n",
      "410               1.0  0.874088\n",
      "411               0.4  0.290586\n",
      "412               0.9  0.577200\n",
      "413               0.0  0.058481\n",
      "414               0.4  0.221919\n",
      "415               1.0  0.542335\n",
      "416               0.5  0.334489\n",
      "417               0.5  0.198626\n",
      "418               0.7  0.419000\n",
      "419               0.1  0.038250\n",
      "420               0.8  0.488695\n",
      "421               0.2  0.137775\n",
      "422               0.8  0.364895\n",
      "423               0.7  0.465734\n",
      "424               0.2  0.200787\n",
      "425               0.9  0.534200\n",
      "426               0.4  0.147631\n",
      "427               0.4  0.265351\n",
      "428               0.4  0.352502\n",
      "429               0.4  0.463512\n",
      "430               0.4  0.459028\n",
      "431               0.7  0.547772\n",
      "432               0.0  0.003334\n",
      "433               0.1  0.071029\n",
      "434               0.8  0.505289\n",
      "435               0.4  0.327884\n",
      "436               0.4  0.208498\n",
      "437               0.0  0.075664\n",
      "438               0.7  0.397943\n",
      "439               0.2  0.080871\n",
      "440               0.9  0.467620\n",
      "441               0.7  0.575642\n",
      "442               0.0  0.040883\n",
      "443               0.5  0.234388\n",
      "444               0.8  0.640160\n",
      "445               0.7  0.319766\n",
      "446               0.8  0.368960\n",
      "447               0.0  0.019914\n",
      "448               0.0  0.021389\n",
      "449               0.6  0.210215\n",
      "450               1.0  0.516232\n"
     ]
    }
   ],
   "source": [
    "# Merge the scores for all systems into a single dataframe\n",
    "all_system_scores = pd.concat(system_scores.values(), keys=system_scores.keys(), axis=1)\n",
    "\n",
    "# Print the scores for all systems\n",
    "print(all_system_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the qrels file\n",
    "qrels_file_path = 'qrels.trec8.adhoc.csv'\n",
    "qrels_df = pd.read_csv(qrels_file_path, sep=' ', header=None, names=['query_id', 'ignore', 'doc_id', 'relevance'])\n",
    "\n",
    "# Get a list of all input files in the input directory\n",
    "input_files = glob.glob('input/*.csv')\n",
    "\n",
    "# Create an empty dictionary to store the system scores\n",
    "system_scores = {}\n",
    "\n",
    "# Loop through each input file\n",
    "for filename in input_files:\n",
    "    # Load the input file\n",
    "    input_df = pd.read_csv(filename, sep='\\t', header=None, names=['query_id', 'ignore', 'doc_id', 'rank', 'score', 'ignore2'])\n",
    "\n",
    "    # Merge the input file with the qrels to get the relevance scores\n",
    "    merged_df = pd.merge(input_df, qrels_df, on=['query_id', 'doc_id'], how='left')\n",
    "\n",
    "    # Compute precision@10 and MAP per query\n",
    "    grouped = merged_df.groupby('query_id')\n",
    "    precisions = grouped.apply(lambda x: np.sum(x['relevance'].iloc[:10]) / 10)\n",
    "    avg_precisions = grouped.apply(lambda x: np.sum(x['relevance'] * np.cumsum(x['relevance']) / np.arange(1, len(x['relevance']) + 1)) / np.sum(x['relevance']))\n",
    "\n",
    "    # Store the scores for this system\n",
    "    system_name = filename.split('/')[-1].split('.')[0]\n",
    "    system_scores[system_name] = pd.DataFrame({'precision@10': precisions, 'MAP': avg_precisions})\n",
    "\n",
    "# Merge the scores for all systems into a single dataframe\n",
    "all_system_scores = pd.concat(system_scores.values(), keys=system_scores.keys(), axis=1)\n",
    "\n",
    "# Print the scores for all systems\n",
    "print(all_system_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Temp/ipykernel_12172/3395548420.py:26: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  avg_precisions = grouped.apply(lambda x: np.sum(x['relevance'] * np.cumsum(x['relevance']) / np.arange(1, len(x['relevance']) + 1)) / np.sum(x['relevance']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  MAP  precision@10\n",
      "input\\input  0.315698         0.478\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Load the qrels file\n",
    "qrels_file_path = 'qrels.trec8.adhoc.csv'\n",
    "qrels_df = pd.read_csv(qrels_file_path, sep=' ', header=None, names=['query_id', 'ignore', 'doc_id', 'relevance'])\n",
    "\n",
    "# Get a list of all input files in the input directory\n",
    "input_files = glob.glob('input/*.csv')\n",
    "\n",
    "# Create an empty dictionary to store the system scores\n",
    "system_scores = {}\n",
    "\n",
    "# Loop through each input file\n",
    "for filename in input_files:\n",
    "    # Load the input file\n",
    "    input_df = pd.read_csv(filename, sep='\\t', header=None, names=['query_id', 'ignore', 'doc_id', 'rank', 'score', 'ignore2'])\n",
    "\n",
    "    # Merge the input file with the qrels to get the relevance scores\n",
    "    merged_df = pd.merge(input_df, qrels_df, on=['query_id', 'doc_id'], how='left')\n",
    "\n",
    "    # Compute precision@10 and MAP per query\n",
    "    grouped = merged_df.groupby('query_id')\n",
    "    precisions = grouped.apply(lambda x: np.sum(x['relevance'].iloc[:10]) / 10)\n",
    "    avg_precisions = grouped.apply(lambda x: np.sum(x['relevance'] * np.cumsum(x['relevance']) / np.arange(1, len(x['relevance']) + 1)) / np.sum(x['relevance']))\n",
    "\n",
    "    # Compute the overall precision@10 and MAP scores for this system\n",
    "    system_name = filename.split('/')[-1].split('.')[0]\n",
    "    overall_precision = precisions.mean()\n",
    "    overall_map = avg_precisions.mean()\n",
    "    system_scores[system_name] = {'precision@10': overall_precision, 'MAP': overall_map}\n",
    "\n",
    "# Convert the system scores dictionary into a dataframe\n",
    "all_system_scores = pd.DataFrame(system_scores).T\n",
    "\n",
    "# Print the scores for all systems\n",
    "print(all_system_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Temp/ipykernel_12172/2495579350.py:26: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  avg_precisions = grouped.apply(lambda x: np.sum(x['relevance'] * np.cumsum(x['relevance']) / np.arange(1, len(x['relevance']) + 1)) / np.sum(x['relevance']))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have length at least 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12172/2495579350.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m# Compute correlation coefficient between precision@10 and MAP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mcorr_coef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpearsonr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_system_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'precision@10'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_system_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'MAP'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Correlation coefficient: {corr_coef:.2f}, p-value: {p_value:.2f}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\acer\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py\u001b[0m in \u001b[0;36mpearsonr\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   4014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4015\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4016\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'x and y must have length at least 2.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4017\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4018\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have length at least 2."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr, ttest_rel\n",
    "\n",
    "# Load the qrels file\n",
    "qrels_file_path = 'qrels.trec8.adhoc.csv'\n",
    "qrels_df = pd.read_csv(qrels_file_path, sep=' ', header=None, names=['query_id', 'ignore', 'doc_id', 'relevance'])\n",
    "\n",
    "# Get a list of all input files in the input directory\n",
    "input_files = glob.glob('input/*.csv')\n",
    "\n",
    "# Create an empty dictionary to store the system scores\n",
    "system_scores = {}\n",
    "\n",
    "# Loop through each input file\n",
    "for filename in input_files:\n",
    "    # Load the input file\n",
    "    input_df = pd.read_csv(filename, sep='\\t', header=None, names=['query_id', 'ignore', 'doc_id', 'rank', 'score', 'ignore2'])\n",
    "\n",
    "    # Merge the input file with the qrels to get the relevance scores\n",
    "    merged_df = pd.merge(input_df, qrels_df, on=['query_id', 'doc_id'], how='left')\n",
    "\n",
    "    # Compute precision@10 and MAP per query\n",
    "    grouped = merged_df.groupby('query_id')\n",
    "    precisions = grouped.apply(lambda x: np.sum(x['relevance'].iloc[:10]) / 10)\n",
    "    avg_precisions = grouped.apply(lambda x: np.sum(x['relevance'] * np.cumsum(x['relevance']) / np.arange(1, len(x['relevance']) + 1)) / np.sum(x['relevance']))\n",
    "\n",
    "    # Compute the overall precision@10 and MAP scores for this system\n",
    "    system_name = filename.split('/')[-1].split('.')[0]\n",
    "    overall_precision = precisions.mean()\n",
    "    overall_map = avg_precisions.mean()\n",
    "    system_scores[system_name] = {'precision@10': overall_precision, 'MAP': overall_map}\n",
    "\n",
    "# Convert the system scores dictionary into a dataframe\n",
    "all_system_scores = pd.DataFrame(system_scores).T\n",
    "\n",
    "# Compute correlation coefficient between precision@10 and MAP\n",
    "corr_coef, p_value = pearsonr(all_system_scores['precision@10'], all_system_scores['MAP'])\n",
    "print(f'Correlation coefficient: {corr_coef:.2f}, p-value: {p_value:.2f}')\n",
    "\n",
    "# Compute significance testing using paired t-test\n",
    "p_value = ttest_rel(all_system_scores['precision@10'], all_system_scores['MAP'])[1]\n",
    "print(f'Paired t-test p-value: {p_value:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
